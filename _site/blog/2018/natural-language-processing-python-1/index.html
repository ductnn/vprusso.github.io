<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="msvalidate.01" content="5E7827CBC3E6F12865C285B3020A9C95" />

  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/blog/2018/natural-language-processing-python-1/">
  <link rel="alternate" type="application/rss+xml" title="Vincent Russo" href="http://localhost:4000/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Vincent Russo</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/blog/">Blog</a>
          
        
          
        
          
          <a class="page-link" href="/cv/">Resume/CV</a>
          
        
          
        
          
          <a class="page-link" href="/">Home</a>
          
        
          
        
          
          <a class="page-link" href="/music/">Music</a>
          
        
          
          <a class="page-link" href="/projects/">Projects</a>
          
        
          
          <a class="page-link" href="/publications/">Publications</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/teaching/">Teaching</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

    <header class="post-header">
        <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59145213-1', 'auto');
  ga('send', 'pageview');

</script>
        <h1 class="post-title">Natural Language Processing in Python: Part 1 -- Introduction</h1>
        <p class="post-meta">Jan 3, 2018</p>
    </header>

    <article class="post-content">
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- blog -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7213376997288299"
     data-ad-slot="4540332365"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
        <script src="https://apis.google.com/js/platform.js"></script>

<h2 id="welcome-to-natural-language-processing-in-python-part-1">Welcome to Natural Language Processing in Python (Part 1)</h2>

<p>This is the first in a series of tutorial posts on natural language processing (NLP). Each post will correspond directly to a YouTube video that covers the respective content. The YouTube link for this post is embedded below:</p>

<div style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/tP783g97C5o" frameborder="0" allowfullscreen=""></iframe>
</div>

<p>The intended audience for this series of posts on NLP is expected to have some rudimentary programming experience and to also be fairly comfortable in a command line environemnt. Exposure to NLP is not assumed, and we’ll be covering some of the salient points of this field with plenty of example programs. If you would like further resources on NLP beyond what is found in the scope of this series, I would recommend the following resources:</p>

<ol>
  <li><em><a href="http://www.nltk.org/book/">Natural Language Processing with Python</a> by Edward Loper, Ewan Klein, and Steven Bird:</em></li>
</ol>

<p>This book is particularly well suited to someone who is also a beginner to Python as the book goes back and forth between NLP concepts and Python concepts. The flow and content of this tutorial series on my YouTube channel will follow a similar trajectory to the one found in this book. In addition to the book, there is also a corresponding website that is completely accessible online for free in the link above.</p>

<ol>
  <li><em><a href="https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ">Natural language processing playlist</a> from YouTuber sentdex:</em></li>
</ol>

<p>I have always quite enjoyed sentdex’s teaching style and breadth of content. If you are unfamiliar with this YouTuber, I certainly recommend looking at his channel.</p>

<p>Indeed, inspiration from the above two resources has been an influence in this series on natural language processing. Furthermore, if you would like to explore more programming tutorials, primarily at this moment focused on the Python programming language, please do consider subscribing to <a href="https://www.youtube.com/channel/UCFxcvyt2Ucq5IL0_1Njzqlg">my YouTube channel</a> and checking out the present offerings:</p>

<center>
<div class="g-ytsubscribe" data-channelid="UCFxcvyt2Ucq5IL0_1Njzqlg" data-layout="full" data-count="default"></div><br /> 
</center>

<p>Table of Contents of this tutorial:</p>

<ul>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-1/">Part 1: Introduction</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-2/">Part 2: Accessing Text Resources</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-3/">Part 3: Generating Word Clouds</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-4/">Part 4: WordNet</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-5/">Part 5: Stemming and Lemmatization</a></p>
  </li>
</ul>

<p>With that out of the way, let us proceed to setting up what we require in order to do some natural language processing in Python.</p>

<h2 id="installing-the-natural-language-toolkit">Installing the Natural Language Toolkit</h2>

<p>Our goal in this post is to install the NLTK (Natural Language ToolKit) module in Python and to do a few rudimentary natural language processing commands.</p>

<p>First, let us go ahead and open up a terminal to install the <a href="http://www.nltk.org/">NLTK module</a>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">nltk</span>
</code></pre>
</div>

<p>Next, we will be installing various collections of text. These collections involve books, chat logs, and other bodies of text-based work. These datasets are a valuable resource, especially for learning the basics of natural language processing by experimenting on these sets of text data. Open a Python shell and run the following command:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span> 
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
</code></pre>
</div>

<p>Running this command will open a dialog box that should look like the following screenshot:</p>

<p align="center">
    <center>
        <figure>
            <img src="https://i.imgur.com/GZ2BW0X.png" alt="NLTK download dialog box." />
        </figure>
    </center>
</p>

<p>Due to the utility of the content provided here, it would be worthwhile to download the entire collection of text provided from NLTK. Note that this will take a few minutes, as the size of the collection of text is quite large. Once that finishes downloading, we can proceed to actually doing some natural language processing.</p>

<h2 id="basic-natural-language-processing">Basic Natural Language Processing</h2>

<p>In this section, we shall load in a specific text resource and use that for our experimentation. For the sake of example, let us load in the “Alice in Wonderland” text via NLTKs Gutenberg module.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.text</span> <span class="kn">import</span> <span class="n">Text</span>
<span class="n">alice</span> <span class="o">=</span> <span class="n">Text</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">gutenberg</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">'carroll-alice.txt'</span><span class="p">))</span>
</code></pre>
</div>
<p>Let us break down these two lines. In this first line, we import NLTKs <code class="highlighter-rouge">Text</code> function. As an argument, text takes a specific text file and turns it into something that NLTK can understand and manipulate. In the second line, we are making use of the <code class="highlighter-rouge">Text</code> function on the text file <code class="highlighter-rouge">carroll-alice</code>, loaded in from NLTKs Gutenberg module. We then store the result in the <code class="highlighter-rouge">alice</code> variable. “Alice in Wonderland” is only one of several texts offered via the NLTK Gutenberg module. You can see the other offerings by running the following command:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">gutenberg</span><span class="o">.</span><span class="n">fileids</span><span class="p">())</span>
    <span class="p">[</span><span class="s">'austen-emma.txt'</span><span class="p">,</span> <span class="s">'austen-persuasion.txt'</span><span class="p">,</span> <span class="s">'austen-sense.txt'</span><span class="p">,</span> <span class="s">'bible-kjv.txt'</span><span class="p">,</span> <span class="s">'blake-poems.txt'</span><span class="p">,</span> <span class="s">'bryant-stories.txt'</span><span class="p">,</span> <span class="s">'burgess-busterbrown.txt'</span><span class="p">,</span> <span class="s">'carroll-alice.txt'</span><span class="p">,</span> <span class="s">'chesterton-ball.txt'</span><span class="p">,</span> <span class="s">'chesterton-brown.txt'</span><span class="p">,</span> <span class="s">'chesterton-thursday.txt'</span><span class="p">,</span> <span class="s">'edgeworth-parents.txt'</span><span class="p">,</span> <span class="s">'melville-moby_dick.txt'</span><span class="p">,</span> <span class="s">'milton-paradise.txt'</span><span class="p">,</span> <span class="s">'shakespeare-caesar.txt'</span><span class="p">,</span> <span class="s">'shakespeare-hamlet.txt'</span><span class="p">,</span> <span class="s">'shakespeare-macbeth.txt'</span><span class="p">,</span> <span class="s">'whitman-leaves.txt'</span><span class="p">]</span>  
</code></pre>
</div>

<p>Now that we have the “Alice in Wonderland” text loaded in, let us perform a few rudimentary natural language processing tasks on this content. Determining the number of words (or more specifically, tokens), in a text can be found by:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alice</span><span class="p">))</span>
    <span class="mi">34110</span>    
</code></pre>
</div>

<p>Similarly, we can determine the number of unique words in “Alice in Wonderland” by using Pythons <code class="highlighter-rouge">set</code> function</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">alice</span><span class="p">)))</span>
    <span class="mi">3016</span> 
</code></pre>
</div>

<p>If we wish to determine how many times a specific word occurs in the text, we can use Pythons <code class="highlighter-rouge">count</code> function. For instance, the word “Alice” occurs 396 times:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">alice</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s">"Alice"</span><span class="p">))</span>
    <span class="mi">396</span> 
</code></pre>
</div>

<p>We may also determine the <strong>concordance</strong> of a word; the occurence and context of a specific word. Determining the concordance of the word <code class="highlighter-rouge">Alice</code> can be done so as:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">alice</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="s">"Alice"</span><span class="p">)</span>
    <span class="n">Alice</span> <span class="s">' s Adventures in Wonderland by Lewi</span><span class="err">
</span><span class="s">    ] CHAPTER I . Down the Rabbit - Hole Alice was beginning to get very tired of s</span><span class="err">
</span><span class="s">    what is the use of a book ,'</span> <span class="n">thought</span> <span class="n">Alice</span> <span class="s">' without pictures or conversation ?</span><span class="err">
</span><span class="s">    so VERY remarkable in that ; nor did Alice think it so VERY much out of the way</span><span class="err">
</span><span class="s">    looked at it , and then hurried on , Alice started to her feet , for it flashed</span><span class="err">
</span><span class="s">     hedge . In another moment down went Alice after it , never once considering ho</span><span class="err">
</span><span class="s">    ped suddenly down , so suddenly that Alice had not a moment to think about stop</span><span class="err">
</span><span class="s">    she fell past it . '</span> <span class="n">Well</span> <span class="err">!</span><span class="s">' thought Alice to herself , '</span> <span class="n">after</span> <span class="n">such</span> <span class="n">a</span> <span class="n">fall</span> <span class="k">as</span> 
    <span class="n">down</span> <span class="p">,</span> <span class="n">I</span> <span class="n">think</span> <span class="o">--</span><span class="s">' ( for , you see , Alice had learnt several things of this so</span><span class="err">
</span><span class="s">    tude or Longitude I '</span> <span class="n">ve</span> <span class="n">got</span> <span class="n">to</span> <span class="err">?</span><span class="s">' ( Alice had no idea what Latitude was , or L</span><span class="err">
</span><span class="s">     . There was nothing else to do , so Alice soon began talking again . '</span> <span class="n">Dinah</span> <span class="s">'</span><span class="err">
</span><span class="s">    cats eat bats , I wonder ?'</span> <span class="n">And</span> <span class="n">here</span> <span class="n">Alice</span> <span class="n">began</span> <span class="n">to</span> <span class="n">get</span> <span class="n">rather</span> <span class="n">sleepy</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">wen</span>
    <span class="n">dry</span> <span class="n">leaves</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">fall</span> <span class="n">was</span> <span class="n">over</span> <span class="o">.</span> <span class="n">Alice</span> <span class="n">was</span> <span class="ow">not</span> <span class="n">a</span> <span class="n">bit</span> <span class="n">hurt</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">she</span> <span class="n">jumped</span> 
     <span class="ow">not</span> <span class="n">a</span> <span class="n">moment</span> <span class="n">to</span> <span class="n">be</span> <span class="n">lost</span> <span class="p">:</span> <span class="n">away</span> <span class="n">went</span> <span class="n">Alice</span> <span class="n">like</span> <span class="n">the</span> <span class="n">wind</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">was</span> <span class="n">just</span> <span class="ow">in</span> <span class="n">time</span>
     <span class="n">but</span> <span class="n">they</span> <span class="n">were</span> <span class="nb">all</span> <span class="n">locked</span> <span class="p">;</span> <span class="ow">and</span> <span class="n">when</span> <span class="n">Alice</span> <span class="n">had</span> <span class="n">been</span> <span class="nb">all</span> <span class="n">the</span> <span class="n">way</span> <span class="n">down</span> <span class="n">one</span> <span class="n">side</span> <span class="n">a</span>
    <span class="n">on</span> <span class="n">it</span> <span class="k">except</span> <span class="n">a</span> <span class="n">tiny</span> <span class="n">golden</span> <span class="n">key</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">Alice</span> <span class="s">' s first thought was that it might </span><span class="err">
</span><span class="s">    and to her great delight it fitted ! Alice opened the door and found that it le</span><span class="err">
</span><span class="s">    ead would go through ,'</span> <span class="n">thought</span> <span class="n">poor</span> <span class="n">Alice</span> <span class="p">,</span> <span class="s">' it would be of very little use w</span><span class="err">
</span><span class="s">    ay things had happened lately , that Alice had begun to think that very few thi</span><span class="err">
</span><span class="s">    ertainly was not here before ,'</span> <span class="n">said</span> <span class="n">Alice</span> <span class="p">,)</span> <span class="ow">and</span> <span class="nb">round</span> <span class="n">the</span> <span class="n">neck</span> <span class="n">of</span> <span class="n">the</span> <span class="n">bottle</span> 
    <span class="n">ay</span> <span class="s">' Drink me ,'</span> <span class="n">but</span> <span class="n">the</span> <span class="n">wise</span> <span class="n">little</span> <span class="n">Alice</span> <span class="n">was</span> <span class="ow">not</span> <span class="n">going</span> <span class="n">to</span> <span class="n">do</span> <span class="n">THAT</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">hurry</span> 
    <span class="n">bottle</span> <span class="n">was</span> <span class="n">NOT</span> <span class="n">marked</span> <span class="s">' poison ,'</span> <span class="n">so</span> <span class="n">Alice</span> <span class="n">ventured</span> <span class="n">to</span> <span class="n">taste</span> <span class="n">it</span> <span class="p">,</span> <span class="ow">and</span> <span class="n">finding</span> <span class="n">i</span>
    <span class="o">*</span> <span class="o">*</span> <span class="s">' What a curious feeling !'</span> <span class="n">said</span> <span class="n">Alice</span> <span class="p">;</span> <span class="s">' I must be shutting up like a tel</span><span class="err">
</span><span class="s">     for it might end , you know ,'</span> <span class="n">said</span> <span class="n">Alice</span> <span class="n">to</span> <span class="n">herself</span> <span class="p">,</span> <span class="s">' in my going out altog</span><span class="err">
</span><span class="s">    garden at once ; but , alas for poor Alice ! when she got to the door , she fou  </span><span class="err">
</span></code></pre>
</div>

<p>Note that the output of the <code class="highlighter-rouge">concordance</code> command shows where the word occurs in the text, and also enough of the sentence to provide context of usage.</p>

<p>Next, let us create something a bit more visual in terms of output. We can generate what is called a <strong>dispersion plot</strong>. This plot will show a plot of the location where a word is in the text. As an example, let us generate a dispersion plot of the words “Alice”, “Rabbit”, “Hatter”, and “Queen” from the “Alice in Wonderland” text.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">alice</span><span class="o">.</span><span class="n">dispersion_plot</span><span class="p">([</span><span class="s">"Alice"</span><span class="p">,</span> <span class="s">"Rabbit"</span><span class="p">,</span> <span class="s">"Hatter"</span><span class="p">,</span> <span class="s">"Queen"</span><span class="p">])</span>
</code></pre>
</div>
<p>Running the above line yields the following plot:</p>

<p align="center">
    <center>
        <figure>
            <img src="https://i.imgur.com/RVM4nOY.png" alt="Dispersion plot of the words Alice, Rabbit, Hatter, and Queen from Alice in Wonderland." />
        </figure>
    </center>
</p>

<p>The plot shows us that the word “Alice” is consistently used throughout the entire text, while the word “Queen” is found closer to the end of the text. This makes sense, since Alice does not encounter the Red Queen until later in the  book.</p>

<h2 id="frequency-distributions-of-text">Frequency Distributions of Text</h2>

<p>We may make use of NLTK’s frequency distribution function to determine the most frequent words (specifically tokens), that are used in a given text.</p>

<p>As an example, say we wish to determine the most frequent tokens in “Alice in Wonderland”. The first step would be to use NLTK to generate a frequency distribution dictionary-like object like so:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">fdist</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">alice</span><span class="p">)</span>
</code></pre>
</div>

<p>We may now make use of the <code class="highlighter-rouge">fdist</code> object to do some cursory analysis. For instance, we may plot the top 50 most common words in “Alice in Wonderland” by creating a cumulative plot:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">fdist</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<p>Running the above line will generate the following</p>

<p align="center">
    <center>
        <figure>
            <img src="https://i.imgur.com/jtIG8PX.png" alt="Cumulative plot of words used in Alice in Wonderland." />
        </figure>
    </center>
</p>

<p>Observe that the x-axis consists of punctuation, which may or may not be precisely what we are going for. It is possible to remove this from the words that we plot by filtering out the punctuation.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">fdist_no_punc</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="nb">dict</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">freq</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">fdist</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()))</span>
<span class="n">fdist_no_punc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"50 most common tokens (no punctuation)"</span><span class="p">)</span>
</code></pre>
</div>

<p>The only non-standard Python code that we are making use of above is to convert the dictionary object that we filter the punctuation from and convert to a NLTK <code class="highlighter-rouge">FreqDist</code> object. The first line then consists of a <code class="highlighter-rouge">FreqDist</code> object soley consisting of non-punctuation tokens. The second line is similar to the one we saw before, and produces the following plot.</p>

<p align="center">
    <center>
        <figure>
            <img src="https://i.imgur.com/JCvVl3D.png" alt="Cumulative plot of words used in Alice in Wonderland with no punctuation." />
        </figure>
    </center>
</p>

<p>Without punctuation, this plot gives us a bit more useful information. However, the x-axis still contains common words such as “and”, “the”, “it”, etc. These types of common English words are referred to as <strong>stopwords</strong>. NLTK provides a method to identify such words.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">stopwords</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)</span>
</code></pre>
</div>

<p>We may then combine the method used above to filter out punctuation so that we also filter out stopwords.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">fdist_no_punc_no_stopwords</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="nb">dict</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">freq</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">fdist</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span> <span class="ow">and</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()))</span>
</code></pre>
</div>

<p>Once we have filtered out both punctuation and stopwords, we can plot the resulting frequency distribution</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">fdist_no_punc_no_stopwords</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"50 most common tokens (no stopwords or punctuation)"</span><span class="p">)</span>
</code></pre>
</div>

<p>This generates the following cumulative plot:</p>

<p align="center">
    <center>
        <figure>
            <img src="https://i.imgur.com/QX36ey8.png" alt="Cumulative plot of words used in Alice in Wonderland. with no punctuation or stopwords." />
        </figure>
    </center>
</p>

<p>By excluding both punctuation and stopwords, this plot gives us a more informative view of the frequency distribution of words in “Alice in Wonderland”.</p>

<h2 id="conclusion">Conclusion</h2>

<p>That wraps up this introduction tutorial on natural language processing in Python. In the next tutorial, we will go over further ways in which you can access the text resources that are provided to you by NLTK.</p>

<p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-2/">Part 2 of Natural Language Processing in Python</a></p>

<p>Table of Contents of this tutorial:</p>

<ul>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-1/">Part 1: Introduction</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-2/">Part 2: Accessing Text Resources</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-3/">Part 3: Generating Word Clouds</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-4/">Part 4: WordNet</a></p>
  </li>
  <li>
    <p><a href="http://vprusso.github.io/blog/2018/natural-language-processing-python-5/">Part 5: Stemming and Lemmatization</a></p>
  </li>
</ul>


        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- blog -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7213376997288299"
     data-ad-slot="4540332365"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </article>
  
    
        <div id="disqus_thread"></div>
            <script type="text/javascript">
                /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
                var disqus_shortname = 'vprusso'; // required: replace example with your forum shortname
                // var disqus_developer = 1; // Comment out when the site is live
                var disqus_identifier = "/blog/2018/natural-language-processing-python-1/";

                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    

    
    <h2>Related Posts:</h2>
    <ul>
      
      
        
        
          
            <li>
              <h3>
                <a href="/blog/2018/natural-language-processing-python-5/">
                  Natural Language Processing in Python: Part 5 -- Stemming and Lemmatization
                  <small>10 Jan 2018</small>
                </a>
              </h3>
            </li>
            
            
      
        
        
          
            <li>
              <h3>
                <a href="/blog/2018/natural-language-processing-python-4/">
                  Natural Language Processing in Python: Part 4 -- WordNet
                  <small>09 Jan 2018</small>
                </a>
              </h3>
            </li>
            
            
      
        
        
          
            <li>
              <h3>
                <a href="/blog/2018/natural-language-processing-python-3/">
                  Natural Language Processing in Python: Part 3 -- Generating Word Clouds
                  <small>08 Jan 2018</small>
                </a>
              </h3>
            </li>
            
            
      
        
          

      
      
    </ul>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Vincent Russo</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Vincent Russo</li>
          <li><a href="mailto:vincentrusso1@gmail.com">vincentrusso1@gmail.com</a></li>
        </ul>
      </div>

	  <div class="footer-col  footer-col-2">
	   <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/vprusso">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">Github</span>
            </a>
          </li>
          
		  
	  
		  <li>
		    <a href="https://ca.linkedin.com/in/vrusso11" class="icon-17 linkedin" title="LinkedIn">
		      <span class="icon  icon--linkedin">
		       <svg viewBox="0 0 512 512">
			<path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z"
			/>
		      </svg>
		      </span>
		      <span class="username">Linkedin</span>
		      <!--[if lt IE 9]><em>LinkedIn</em><![endif]--></a>
		  </li>
	  
	  
	  
		<li>
			<a href="https://scholar.google.ca/citations?user=dJEXPiQAAAAJ&hl=en" class="icon  icon--googlescholar" title="GoogleScholar">
			<span class="icon icon--googlescholar">
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" viewBox="0 0 16 16">
			<path fill="#000000" d="M14.942 12.57l-4.942-8.235v-3.335h0.5c0.275 0 0.5-0.225 0.5-0.5s-0.225-0.5-0.5-0.5h-5c-0.275 0-0.5 0.225-0.5 0.5s0.225 0.5 0.5 0.5h0.5v3.335l-4.942 8.235c-1.132 1.886-0.258 3.43 1.942 3.43h10c2.2 0 3.074-1.543 1.942-3.43zM3.766 10l3.234-5.39v-3.61h2v3.61l3.234 5.39h-8.468z"></path>
			</svg>
			</span>
			<span class="username">Google Scholar</span>
			<!--[if lt IE 9]><em>GoogleScholar</em><![endif]--></a>
		</li>
	  
	  
        </ul>
      </div>
	  
      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
      
	  	  
			<li><a href="http://stackexchange.com/users/412832/vincent-russo" class="icon-23 stackoverflow" title="StackOverflow">
			<span class="icon  icon--stackoverflow">
			<svg viewBox="0 0 512 512">
			<path d="M294.8 361.2l-122 0.1 0-26 122-0.1L294.8 361.2zM377.2 213.7L356.4 93.5l-25.7 4.5 20.9 120.2L377.2 213.7zM297.8 301.8l-121.4-11.2 -2.4 25.9 121.4 11.2L297.8 301.8zM305.8 267.8l-117.8-31.7 -6.8 25.2 117.8 31.7L305.8 267.8zM321.2 238l-105-62 -13.2 22.4 105 62L321.2 238zM346.9 219.7l-68.7-100.8 -21.5 14.7 68.7 100.8L346.9 219.7zM315.5 275.5v106.5H155.6V275.5h-20.8v126.9h201.5V275.5H315.5z"/>
			</svg>
			</span>
			<span class="username">StackOverflow</span>
			<!--[if lt IE 9]><em>StackOverflow</em><![endif]--></a></li>
		 

          
          <li>
            <a href="https://twitter.com/captainhamptons">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">Twitter</span>
            </a>
          </li>
          
		  
		  
          <li>
            <a href="https://soundcloud.com/captainhampton">
              <span class="icon  icon--soundcloud">
				<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" viewBox="0 0 16 16">
					<path fill="#000000" d="M13.937 8.034c-0.283 0-0.552 0.055-0.798 0.154-0.164-1.787-1.723-3.188-3.625-3.188-0.465 0-0.917 0.088-1.317 0.237-0.156 0.058-0.197 0.117-0.197 0.233v6.292c0 0.121 0.098 0.222 0.221 0.234 0.005 0.001 5.68 0.003 5.717 0.003 1.139 0 2.062-0.888 2.062-1.983s-0.924-1.983-2.063-1.983zM6.25 12h0.5l0.25-3.503-0.25-3.497h-0.5l-0.25 3.497zM4.75 12h-0.5l-0.25-2.543 0.25-2.457h0.5l0.25 2.5zM2.25 12h0.5l0.25-2-0.25-2h-0.5l-0.25 2zM0.25 11h0.5l0.25-1-0.25-1h-0.5l-0.25 1z"></path>
				</svg>
              </span>

              <span class="username">Soundcloud</span>
            </a>
          </li>
          
		  
		  
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text"></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
